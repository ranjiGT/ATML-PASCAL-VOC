{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc46cded",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [278, 15617]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f342d73cc646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;31m# split train into labeled and unlabeled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mX_train_lab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_unlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_lab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_unlab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ATMLVOC\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ATMLVOC\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \"\"\"\n\u001b[0;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ATMLVOC\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 320\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [278, 15617]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition\n",
    "#path = r'C:\\Users\\user/'\n",
    "\n",
    "color_layout_features = pd.read_pickle(\"color_layout_descriptor.pkl\")\n",
    "bow_surf  = pd.read_pickle(\"bow_surf.pkl\")\n",
    "color_hist_features  = pd.read_pickle(\"hist.pkl\")\n",
    "labels  = pd.read_pickle(\"labels.pkl\")\n",
    "\n",
    "#color_layout_features  = pd.read_pickle(path + \"/color_layout_descriptor.pkl\")\n",
    "#bow_surf  = pd.read_pickle(path + \"/bow_surf.pkl\")\n",
    "#color_hist_features  = pd.read_pickle(path + \"/hist.pkl\")\n",
    "#labels  = pd.read_pickle(path +\"/labels.pkl\")\n",
    "\n",
    "#print(color_layout_features)\n",
    "\n",
    "def scale(X, x_min, x_max):\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1\n",
    "    return x_min + nom/denom \n",
    "\n",
    "\n",
    "color_layout_features_scaled = scale(color_layout_features, 0, 1)\n",
    "color_hist_features_scaled = scale(color_hist_features, 0, 1)\n",
    "bow_surf_scaled = scale(bow_surf, 0, 1)\n",
    "\n",
    "\n",
    "features = np.hstack([color_layout_features_scaled, color_hist_features_scaled, bow_surf_scaled])\n",
    "# define dataset\n",
    "\n",
    "X, Y = features,labels\n",
    "#X = normalize(X)\n",
    "#pca = decomposition.PCA(n_components=100)\n",
    "#pca.fit(X)\n",
    "#X = pca.transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.50, random_state=1, stratify=Y)\n",
    "# split train into labeled and unlabeled\n",
    "X_train_lab, X_test_unlab, y_train_lab, y_test_unlab = train_test_split(X_train, y_train, test_size=0.50, random_state=1, stratify=y_train)\n",
    "# create the training dataset input\n",
    "X_train_mixed = concatenate((X_train_lab, X_test_unlab))\n",
    "# create \"no label\" for unlabeled data\n",
    "nolabel = [-1 for _ in range(len(y_test_unlab))]\n",
    "# recombine training dataset labels\n",
    "y_train_mixed = concatenate((y_train_lab, nolabel))\n",
    "\n",
    "\n",
    "# normalization\n",
    "def normalize(x):\n",
    "    return (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "\n",
    "\"\"\"\n",
    "def get_data(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.6, random_state = 0)\n",
    "    rng = np.random.RandomState(42)\n",
    "    random_unlabeled_points = rng.rand(len(X_train)) < 0.1\n",
    "    y_train[random_unlabeled_points] = -1\n",
    "    #\n",
    "    index, = np.where(y_train != -1)\n",
    "    label_X_train = X_train[index,:]\n",
    "    label_y_train = y_train[index]\n",
    "    index, = np.where(y_train == -1)\n",
    "    unlabel_X_train = X_train[index,:]\n",
    "    unlabel_y = -1*np.ones(unlabel_X_train.shape[0]).astype(int)\n",
    "    return label_X_train, label_y_train, unlabel_X_train, unlabel_y, X_test, y_test\n",
    "\n",
    "label_X_train, label_y_train, unlabel_X_train, unlabel_y, X_test, y_test = get_data(X,Y)\n",
    "\"\"\"\n",
    "# import\n",
    "from semisupervised.TSVM import S3VM\n",
    "\n",
    "model = S3VM()\n",
    "#model.fit(X_train_mixed, _train_mixed)\n",
    "model.fit(np.vstack((X_train_lab, X_test_unlab)), np.append(y_train_lab, nolabel))\n",
    "#model.fit(np.vstack((label_X_train, unlabel_X_train)), np.append(label_y_train, unlabel_y))\n",
    "# predict\n",
    "predict = model.predict(X_test)\n",
    "acc = metrics.accuracy_score(y_test, predict)\n",
    "# metric\n",
    "print(\"accuracy\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
